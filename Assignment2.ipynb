{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a507c4b-ce89-47e5-b453-5f8eb86ce49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   max_depth  Avg Train R2  Avg Test R2  Avg Train MSE  Avg Test MSE\n",
      "0        NaN      1.000000     0.836830   7.785962e-30   1338.402821\n",
      "1        3.0      0.627589     0.541194   3.085552e+03   3703.025204\n",
      "2        5.0      0.828554     0.734102   1.419969e+03   2119.158214\n",
      "3        7.0      0.925080     0.788277   6.203361e+02   1696.785777\n",
      "4        9.0      0.970724     0.836182   2.420654e+02   1338.424835\n",
      "   min_samples_split  Avg Train R2  Avg Test R2  Avg Train MSE  Avg Test MSE\n",
      "0                  2      1.000000     0.836830   7.785962e-30   1338.402821\n",
      "1                  3      0.996342     0.840239   3.030147e+01   1305.278580\n",
      "2                  4      0.992238     0.827729   6.432489e+01   1412.508982\n",
      "3                  5      0.987015     0.833296   1.076485e+02   1383.132585\n",
      "4                  6      0.980710     0.841549   1.598003e+02   1305.328790\n",
      "    max_depth  min_split  Avg Train R2  Avg Test R2  Avg Train MSE  Avg Test MSE\n",
      "0         NaN          2         1.000        0.837          0.000      1338.403\n",
      "1         NaN          3         0.996        0.840         30.301      1305.279\n",
      "2         NaN          4         0.992        0.828         64.325      1412.509\n",
      "3         NaN          5         0.987        0.833        107.648      1383.133\n",
      "4         NaN          6         0.981        0.842        159.800      1305.329\n",
      "5         3.0          2         0.628        0.541       3085.552      3703.025\n",
      "6         3.0          3         0.628        0.541       3085.552      3703.025\n",
      "7         3.0          4         0.628        0.541       3085.552      3703.025\n",
      "8         3.0          5         0.628        0.541       3085.552      3703.025\n",
      "9         3.0          6         0.628        0.541       3085.552      3703.025\n",
      "10        5.0          2         0.829        0.734       1419.969      2119.158\n",
      "11        5.0          3         0.829        0.734       1420.098      2116.965\n",
      "12        5.0          4         0.828        0.734       1420.480      2116.965\n",
      "13        5.0          5         0.828        0.734       1421.050      2117.110\n",
      "14        5.0          6         0.828        0.735       1426.339      2116.378\n",
      "15        7.0          2         0.925        0.788        620.336      1696.786\n",
      "16        7.0          3         0.924        0.791        627.877      1675.824\n",
      "17        7.0          4         0.923        0.790        636.048      1685.856\n",
      "18        7.0          5         0.921        0.793        651.600      1660.654\n",
      "19        7.0          6         0.919        0.791        673.771      1681.138\n",
      "20        9.0          2         0.971        0.836        242.065      1338.425\n",
      "21        9.0          3         0.969        0.834        259.687      1351.629\n",
      "22        9.0          4         0.966        0.829        279.063      1402.502\n",
      "23        9.0          5         0.963        0.832        305.702      1390.243\n",
      "24        9.0          6         0.959        0.838        341.967      1328.482\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas\n",
    "# !pip install seaborn\n",
    "# !pip install matplotlib.pyplot\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Import training data\n",
    "training_data = pd.read_csv('steel.csv')\n",
    "X_training = training_data[['normalising_temperature', 'tempering_temperature', 'percent_silicon', 'percent_chromium', 'percent_copper', \n",
    "                            'percent_nickel', 'percent_sulphur', 'percent_carbon', 'percent_manganese']]\n",
    "Y_training = training_data['tensile_strength']\n",
    "# print(X_training)\n",
    "# print(Y_training)\n",
    "\n",
    "\n",
    "# Scatter plot: of every line\n",
    "\"\"\"\n",
    "plot_training = X_training.rename(columns={\n",
    "    'normalising_temperature': 'normalising temp',\n",
    "    'tempering_temperature': 'tempering temp',\n",
    "    'percent_silicon': '% silicon',\n",
    "    'percent_chromium': '% chromium',\n",
    "    'percent_copper': '% copper',\n",
    "    'percent_nickel': '% nickel',\n",
    "    'percent_sulphur': '% sulphur',\n",
    "    'percent_carbon': '% carbon',\n",
    "    'percent_manganese': '% manganese',\n",
    "})\n",
    "\n",
    "pd.plotting.scatter_matrix(\n",
    "    plot_training[['normalising temp', 'tempering temp', '% silicon', \n",
    "                '% chromium', '% copper', '% nickel', \n",
    "                '% sulphur', '% carbon', '% manganese']],\n",
    "    figsize=(20, 20),\n",
    "    diagonal='kde'   # histogram or kde on the diagonal\n",
    ")\n",
    "plt.savefig(\"scatter_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# Choose error metrics:\n",
    "scoring = {\n",
    "    'r2': 'r2',\n",
    "    'mse': 'neg_mean_squared_error',\n",
    "}\n",
    "\n",
    "# List to collect results\n",
    "results_list = []\n",
    "results_list_split = []\n",
    "\n",
    "depth = [None, 3, 5, 7, 9]\n",
    "samples_to_split = [2,3,4,5,6]\n",
    "\n",
    "for d in depth:\n",
    "    # Train our model with the training data\n",
    "    regressor = DecisionTreeRegressor(random_state=0, max_depth=d)\n",
    "    \n",
    "    # Set up 10-fold cross-validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    results = cross_validate(regressor, X_training, Y_training, cv=kf, scoring=scoring, return_train_score=True)\n",
    "    \n",
    "    # Store results in a dict\n",
    "    results_list.append({\n",
    "        \"max_depth\": d,\n",
    "        \"Avg Train R2\": results['train_r2'].mean(),\n",
    "        \"Avg Test R2\": results['test_r2'].mean(),\n",
    "        \"Avg Train MSE\": -results['train_mse'].mean(),   # convert to positive\n",
    "        \"Avg Test MSE\": -results['test_mse'].mean()\n",
    "    })\n",
    "\n",
    "# Create the DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "print(results_df)\n",
    "\n",
    "for s in samples_to_split:\n",
    "    # Train our model with the training data\n",
    "    regressor = DecisionTreeRegressor(random_state=0, min_samples_split=s)\n",
    "    \n",
    "    # Set up 10-fold cross-validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    results = cross_validate(regressor, X_training, Y_training, cv=kf, scoring=scoring, return_train_score=True)\n",
    "    \n",
    "    # Store results in a dict\n",
    "    results_list_split.append({\n",
    "        \"min_samples_split\": s,\n",
    "        \"Avg Train R2\": results['train_r2'].mean(),\n",
    "        \"Avg Test R2\": results['test_r2'].mean(),\n",
    "        \"Avg Train MSE\": -results['train_mse'].mean(),   # convert to positive\n",
    "        \"Avg Test MSE\": -results['test_mse'].mean()\n",
    "    })\n",
    "\n",
    "# Create the DataFrame\n",
    "results_split_df = pd.DataFrame(results_list_split)\n",
    "print(results_split_df)\n",
    "\n",
    "#Now combine them\n",
    "\n",
    "results_list_total = []\n",
    "\n",
    "for d in depth:\n",
    "    for s in samples_to_split:\n",
    "        # Train our model with the training data\n",
    "        regressor = DecisionTreeRegressor(random_state=0, max_depth=d, min_samples_split=s)\n",
    "        \n",
    "        # Set up 10-fold cross-validation\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "        results = cross_validate(regressor, X_training, Y_training, cv=kf, scoring=scoring, return_train_score=True)\n",
    "        \n",
    "        # Store results in a dict\n",
    "        results_list_total.append({\n",
    "            \"max_depth\": d,\n",
    "            \"min_split\": s,\n",
    "            \"Avg Train R2\": round(results['train_r2'].mean(),3),\n",
    "            \"Avg Test R2\": round(results['test_r2'].mean(),3),\n",
    "            \"Avg Train MSE\": round(-results['train_mse'].mean(),3),   # convert to positive\n",
    "            \"Avg Test MSE\": round(-results['test_mse'].mean(),3)\n",
    "        })\n",
    "\n",
    "# Create the DataFrame\n",
    "results_total = pd.DataFrame(results_list_total)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "print(results_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28afd97c-00a5-44f3-b3d8-0273b6caa0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Kernel  Avg Train R2  Avg Test R2  Avg Train MSE  Avg Test MSE\n",
      "0   None           1.0    -0.557285   5.519898e-07  12686.100059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor a in alpha:\\n     # Train our model with the training data\\n    regressor = GaussianProcessRegressor(random_state=0, alpha=a)\\n\\n    model = make_pipeline(StandardScaler(), regressor)\\n\\n    # Set up 10-fold cross-validation\\n    kf = KFold(n_splits=10, shuffle=True, random_state=0)\\n    results = cross_validate(model, X_training, Y_training, cv=kf, scoring=scoring, return_train_score=True)\\n\\n    # Store results in a dict\\n    results_list_alpha.append({\\n        \"Alpha\": a,\\n        \"Avg Train R2\": results[\\'train_r2\\'].mean(),\\n        \"Avg Test R2\": results[\\'test_r2\\'].mean(),\\n        \"Avg Train MSE\": -results[\\'train_mse\\'].mean(),   # convert to positive\\n        \"Avg Test MSE\": -results[\\'test_mse\\'].mean()\\n    })\\n\\n# Create the DataFrame\\nresults_alpha_df = pd.DataFrame(results_list_alpha)\\nprint(results_alpha_df)\\n\\n#Now combine them\\n\\nresults_list_total = []\\n\\nfor k in kernels:\\n    for a in alpha:\\n        # Train our model with the training data\\n        regressor = GaussianProcessRegressor(random_state=0, alpha=a, kernel=k)\\n\\n        model = make_pipeline(StandardScaler(), regressor)\\n\\n        # Set up 10-fold cross-validation\\n        kf = KFold(n_splits=10, shuffle=True, random_state=0)\\n        results = cross_validate(model, X_training, Y_training, cv=kf, scoring=scoring, return_train_score=True)\\n\\n        # Store results in a dict\\n        results_list_total.append({\\n            \"Kernel\": k,\\n            \"Alpha\": a,\\n            \"Avg Train R2\": results[\\'train_r2\\'].mean(),\\n            \"Avg Test R2\": results[\\'test_r2\\'].mean(),\\n            \"Avg Train MSE\": -results[\\'train_mse\\'].mean(),   # convert to positive\\n            \"Avg Test MSE\": -results[\\'test_mse\\'].mean()\\n        })\\n\\n# Create the DataFrame\\nresults_total = pd.DataFrame(results_list_total)\\npd.set_option(\\'display.max_columns\\', None)\\npd.set_option(\\'display.width\\', 200)\\n\\nprint(results_list_total)\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install pandas\n",
    "# !pip install seaborn\n",
    "# !pip install matplotlib.pyplot\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic, ExpSineSquared, DotProduct\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Import training data\n",
    "training_data = pd.read_csv('steel.csv')\n",
    "X_training = training_data[['normalising_temperature', 'tempering_temperature', 'percent_silicon', 'percent_chromium', 'percent_copper', \n",
    "                            'percent_nickel', 'percent_sulphur', 'percent_carbon', 'percent_manganese']]\n",
    "Y_training = training_data['tensile_strength']\n",
    "# print(X_training)\n",
    "# print(Y_training)\n",
    "\n",
    "\n",
    "# Scatter plot: of every line\n",
    "\"\"\"\n",
    "plot_training = X_training.rename(columns={\n",
    "    'normalising_temperature': 'normalising temp',\n",
    "    'tempering_temperature': 'tempering temp',\n",
    "    'percent_silicon': '% silicon',\n",
    "    'percent_chromium': '% chromium',\n",
    "    'percent_copper': '% copper',\n",
    "    'percent_nickel': '% nickel',\n",
    "    'percent_sulphur': '% sulphur',\n",
    "    'percent_carbon': '% carbon',\n",
    "    'percent_manganese': '% manganese',\n",
    "})\n",
    "\n",
    "pd.plotting.scatter_matrix(\n",
    "    plot_training[['normalising temp', 'tempering temp', '% silicon', \n",
    "                '% chromium', '% copper', '% nickel', \n",
    "                '% sulphur', '% carbon', '% manganese']],\n",
    "    figsize=(20, 20),\n",
    "    diagonal='kde'   # histogram or kde on the diagonal\n",
    ")\n",
    "plt.savefig(\"scatter_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# Choose error metrics:\n",
    "scoring = {\n",
    "    'r2': 'r2',\n",
    "    'mse': 'neg_mean_squared_error',\n",
    "}\n",
    "\n",
    "# List to collect results\n",
    "results_list = []\n",
    "results_list_alpha = []\n",
    "\n",
    "#Default kernel (None) uses RBF\n",
    "\n",
    "kernels = [\n",
    "    # RBF\n",
    "    None,\n",
    "\n",
    "]\n",
    "alpha = [0.00001, 0.1, 1, 10, 100]\n",
    "\n",
    "for k in kernels:\n",
    "    # Train our model with the training data\n",
    "    regressor = GaussianProcessRegressor(random_state=0, kernel=k)\n",
    "\n",
    "    #If you remove model and put in regressor instead u get what happens with no normalization\n",
    "    model = make_pipeline(StandardScaler(), regressor)\n",
    "\n",
    "    # Set up 10-fold cross-validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    results = cross_validate(regressor, X_training, Y_training, cv=kf, scoring=scoring, return_train_score=True)\n",
    "    \n",
    "    # Store results in a dict\n",
    "    results_list.append({\n",
    "        \"Kernel\": k,\n",
    "        \"Avg Train R2\": results['train_r2'].mean(),\n",
    "        \"Avg Test R2\": results['test_r2'].mean(),\n",
    "        \"Avg Train MSE\": -results['train_mse'].mean(),   # convert to positive\n",
    "        \"Avg Test MSE\": -results['test_mse'].mean()\n",
    "    })\n",
    "\n",
    "# Create the DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "print(results_df)\n",
    "\"\"\"\n",
    "for a in alpha:\n",
    "     # Train our model with the training data\n",
    "    regressor = GaussianProcessRegressor(random_state=0, alpha=a)\n",
    "    \n",
    "    model = make_pipeline(StandardScaler(), regressor)\n",
    "\n",
    "    # Set up 10-fold cross-validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    results = cross_validate(model, X_training, Y_training, cv=kf, scoring=scoring, return_train_score=True)\n",
    "    \n",
    "    # Store results in a dict\n",
    "    results_list_alpha.append({\n",
    "        \"Alpha\": a,\n",
    "        \"Avg Train R2\": results['train_r2'].mean(),\n",
    "        \"Avg Test R2\": results['test_r2'].mean(),\n",
    "        \"Avg Train MSE\": -results['train_mse'].mean(),   # convert to positive\n",
    "        \"Avg Test MSE\": -results['test_mse'].mean()\n",
    "    })\n",
    "\n",
    "# Create the DataFrame\n",
    "results_alpha_df = pd.DataFrame(results_list_alpha)\n",
    "print(results_alpha_df)\n",
    "\n",
    "#Now combine them\n",
    "\n",
    "results_list_total = []\n",
    "\n",
    "for k in kernels:\n",
    "    for a in alpha:\n",
    "        # Train our model with the training data\n",
    "        regressor = GaussianProcessRegressor(random_state=0, alpha=a, kernel=k)\n",
    "        \n",
    "        model = make_pipeline(StandardScaler(), regressor)\n",
    "    \n",
    "        # Set up 10-fold cross-validation\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "        results = cross_validate(model, X_training, Y_training, cv=kf, scoring=scoring, return_train_score=True)\n",
    "        \n",
    "        # Store results in a dict\n",
    "        results_list_total.append({\n",
    "            \"Kernel\": k,\n",
    "            \"Alpha\": a,\n",
    "            \"Avg Train R2\": results['train_r2'].mean(),\n",
    "            \"Avg Test R2\": results['test_r2'].mean(),\n",
    "            \"Avg Train MSE\": -results['train_mse'].mean(),   # convert to positive\n",
    "            \"Avg Test MSE\": -results['test_mse'].mean()\n",
    "        })\n",
    "\n",
    "# Create the DataFrame\n",
    "results_total = pd.DataFrame(results_list_total)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "print(results_list_total)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f5c08-8dc6-4b1f-ae1c-365453f7c580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103047f9-b96e-42eb-838d-c3ad7480a441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
